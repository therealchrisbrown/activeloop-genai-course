{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/therealchrisbrown/test_dataset\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://therealchrisbrown/test_dataset loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "username = \"therealchrisbrown\"\n",
    "dataset_name = \"test_dataset\"\n",
    "ds = deeplake.dataset(f\"hub://{username}/{dataset_name}\")\n",
    "\n",
    "# create column text\n",
    "ds.create_tensor('text', htype=\"text\")\n",
    "\n",
    "# add some texts to the dataset\n",
    "texts = [f\"text {i}\" for i in range(1, 11)]\n",
    "for text in texts:\n",
    "    ds.append({\"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'firstdbf9474d461a19e9333c2fd19b46115348f'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.commit(\"added texts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-10 15:04:53,467 | INFO | SingleProcessIterator initialized 36290\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.:   0%|          | 101/2.00G [00:00<810:02:59, 736B/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Batch 0\n",
      "Sample 0: text 9\n",
      "Sample 1: text 8\n",
      "Sample 2: text 5\n",
      "\n",
      "Batch 1\n",
      "Sample 0: text 7\n",
      "Sample 1: text 1\n",
      "Sample 2: text 3\n",
      "\n",
      "Batch 2\n",
      "Sample 0: text 4\n",
      "Sample 1: text 6\n",
      "Sample 2: text 2\n",
      "\n",
      "Batch 3\n",
      "Sample 0: text 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create PyTorch data loader\n",
    "batch_size = 3\n",
    "train_loader = ds.dataloader()\\\n",
    "    .batch(batch_size)\\\n",
    "    .shuffle()\\\n",
    "    .pytorch()\n",
    "\n",
    "# loop over the elements\n",
    "for i, batch in enumerate(train_loader):\n",
    "    print(f\"Batch {i}\")\n",
    "    samples = batch.get(\"text\")\n",
    "    for j, sample in enumerate(samples):\n",
    "        print(f\"Sample {j}: {sample}\")\n",
    "    print()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class DeepLakePyTorchDataset(Dataset):\n",
    "    def __init__(self, ds):\n",
    "        self.ds = ds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        texts = self.ds.text[idx].text().astype(str)\n",
    "        return { \"text\": texts }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "Sample 0: text 10\n",
      "Sample 1: text 1\n",
      "Sample 2: text 6\n",
      "\n",
      "Batch 1\n",
      "Sample 0: text 4\n",
      "Sample 1: text 3\n",
      "Sample 2: text 5\n",
      "\n",
      "Batch 2\n",
      "Sample 0: text 8\n",
      "Sample 1: text 7\n",
      "Sample 2: text 2\n",
      "\n",
      "Batch 3\n",
      "Sample 0: text 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create PyTorch dataset\n",
    "ds_pt = DeepLakePyTorchDataset(ds)\n",
    "\n",
    "# create PyTorch data loader from PyTorch dataset\n",
    "dataloader_pytorch = DataLoader(ds_pt, batch_size=3, shuffle=True)\n",
    "\n",
    "# loop over the elements\n",
    "for i, batch in enumerate(dataloader_pytorch):\n",
    "    print(f\"Batch {i}\")\n",
    "    samples = batch.get(\"text\")\n",
    "    for j, sample in enumerate(samples):\n",
    "        print(f\"Sample {j}: {sample}\")\n",
    "    print()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "Sample 0: text 5\n",
      "Sample 1: text 4\n",
      "Sample 2: text 10\n",
      "\n",
      "Batch 1\n",
      "Sample 0: text 2\n",
      "Sample 1: text 7\n",
      "Sample 2: text 3\n",
      "\n",
      "Batch 2\n",
      "Sample 0: text 1\n",
      "Sample 1: text 6\n",
      "Sample 2: text 9\n",
      "\n",
      "Batch 3\n",
      "Sample 0: text 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds_view = ds.query(\"select * where contains(text, '1')\")\n",
    "\n",
    "# code that creates a data loader and prints the batches\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class DeepLakePyTorchDataset(Dataset):\n",
    "    def __init__(self, ds):\n",
    "        self.ds = ds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        texts = self.ds.text[idx].text().astype(str)\n",
    "        return { \"text\": texts }\n",
    "\n",
    "# create PyTorch dataset\n",
    "ds_pt = DeepLakePyTorchDataset(ds)\n",
    "\n",
    "# create PyTorch data loader from PyTorch dataset\n",
    "dataloader_pytorch = DataLoader(ds_pt, batch_size=3, shuffle=True)\n",
    "\n",
    "# loop over the elements\n",
    "for i, batch in enumerate(dataloader_pytorch):\n",
    "    print(f\"Batch {i}\")\n",
    "    samples = batch.get(\"text\")\n",
    "    for j, sample in enumerate(samples):\n",
    "        print(f\"Sample {j}: {sample}\")\n",
    "    print()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_view = ds.query(\"select * where contains(text, '1')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://therealchrisbrown/test_dataset', index=Index([(0, 9)]), tensors=['text'])\n"
     ]
    }
   ],
   "source": [
    "print(ds_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "Sample 0: text 3\n",
      "Sample 1: text 10\n",
      "Sample 2: text 6\n",
      "\n",
      "Batch 1\n",
      "Sample 0: text 4\n",
      "Sample 1: text 7\n",
      "Sample 2: text 2\n",
      "\n",
      "Batch 2\n",
      "Sample 0: text 5\n",
      "Sample 1: text 1\n",
      "Sample 2: text 9\n",
      "\n",
      "Batch 3\n",
      "Sample 0: text 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataloader_pytorch = DataLoader(ds_pt, batch_size=3, shuffle=True)\n",
    "\n",
    "# loop over the elements\n",
    "for i, batch in enumerate(dataloader_pytorch):\n",
    "    print(f\"Batch {i}\")\n",
    "    samples = batch.get(\"text\")\n",
    "    for j, sample in enumerate(samples):\n",
    "        print(f\"Sample {j}: {sample}\")\n",
    "    print()\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activeloop-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
